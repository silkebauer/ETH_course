# Exercise: Refreshing R and linear models {#refresher}


## Refreshing R

### Software installation

Download R and RStudio.   

Install the packages `rmarkdown`, `bookdown`, `knitr`, `dplyr`, `tidyr`, `ggplot2`and `arm` by typing `install.packages("rmarkdown")` etc. in the R-console. R-packages need to be installed only once, or after a major update of R.

```{r, eval=FALSE}
install.packages(c("rmarkdown", "bookdown", "knitr", "dplyr", "tidyr", "ggplot2",  "arm", "bookdown"))
```


### Working with R

Writing and editing code is done in a text editor such as Wordpad or RStudio. RStudio is recommended because it is developed by the R development core team, it understands the R language and it communicates with R.  
We write the code in the text file (`.r` or `.rmd`) and send it to the R-console in RStudio using `ctrl + enter`.  

### Working with rmarkdown

Rmarkdown allows knitting text with R code. The option to knit text with R code allows to write analyses reports without having to copy and paste results from the R console into a Word file. We can optionally show or hide R code and insert results directly in the text. Further, for sharing R code, it is extremely helpful to describe what the R code does in the text sections. 

Text is written in plain. Latex notation can be used. Helpful [introductions exist online](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf).

R code is written within R chunks. In the header of the R chunks we can specify how the code, results and messages are shown in the output file. 
By pushing the "Knit" button all R-code is executed and displayed within a html, pdf or word document together with the text. The output format is specified in the header of the rmd-file.  

The R-console is the calculator. R can be used as a simple calculator or we can create objects, such as `x` and apply functions such as `mean()` to the objects. Functions are followed by round brackets `()` whithin which we can provide arguments. In the help file of the functions (open by `?` followed by the name of the function), we can see what arguments a function needs and what default values the arguments have.  


```{r rcodechunk, collapse=TRUE}
# This is R-code, therefore text is outcommented by the hash-tag sign

36/5  # a mathematical expression

x <- c(4,7,3,6,2,7,4,3,4,6,2,8) # a vector, 
# x becomes an object in the R global environment

mean(x) # apply a function to an object

# arguments of functions are defined with a specific order
mean(4,7,3,6,2,7,4,3,4,6,2,8) # is not correct!
# but
mean(c(4,7,3,6,2,7,4,3,4,6,2,8)) # is correct

# check  ?mean  for arguments, order of arguments and default values

```


## Linear regression

### Theory

You find the theory to this exercise in Chapter 11 in the online book [Bayesian Data Analyses Using Linear Models in R and Stan](https://tobiasroth.github.io/BDAEcology/lm.html).


### Fitting a Linear Regression in R

```{r setup, message=FALSE}
library(arm)
library(dplyr)
library(tidyr)
library(ggplot2)
```

 
 
### Data 

We use weight data of snowfinches *Montifringilla nivalis* that have been captured and ringed during the winter months and we ask how the average weight changes with the time of the day.

```{r readdat}
dat <- read.table("data/SFringlistwinter.txt", header=TRUE, sep="\t")
# select winter month
dat <- dat[is.element(dat$month, c(0:3)),]

dat$time.num <- dat$time_hour + dat$time_min/60
plot(dat$time.num, dat$weight, xlab="Hour", ylab="Weight [g]", pch=16, col=rgb(0,0,0,0.5), cex=0.7)
```
 
### Fit the regression using lm

[Theory](https://tobiasroth.github.io/BDAEcology/lm.html#linear-regression)


```{r}
mod <- lm(weight~time.num, data=dat)
mod

plot(dat$time.num, dat$weight, xlab="Hour", ylab="Weight [g]", pch=16, col=rgb(0,0,0,0.5), cex=0.7)
abline(mod, col="brown")
```
 
 *  What does the function `lm` do?
 
 * What are the model parameters and what are their estimates?
 
 * How does the formula of the regression line look like?
 

 
 
### Check the model assumptions

[Theory](https://tobiasroth.github.io/BDAEcology/residualanalysis.html)

```{r diagnostics, fig.cap="Diagnostic residual plots of a normal linear model fitted to simulated data, thus model assumptions are perfectly met. See text for explanation."}
par(mfrow=c(2,2))
plot(mod)

```

* Would you trust this model? Do you think the model assumptions are met?

* Which structures of the data could violate the model assumptions?




### Drawing Conclusions
To answer the question about how strongly $y$ is related to $x$ taking into account statistical uncertainty we look at the estimated slope $\beta_{1}$ and its standard error (SE). The slope $\beta_{1}$  measures how much $y$ increases in average when $x$ is increased by 1 unit. The value of $\beta_{1}$ is calculated from the data at hand. It is therefore, a characteristics of the specific data. However, we would like to draw our conclusions more generally, i.e. also in future, for new data, we expect that $y$ increases by $\beta_{1}$ if $x$ increases by 1. However for these unmeasured, future data $\beta_{1}$  may look differently. No statistical method can exactly predict how $\beta_{1}$  will look for future data. However, if we assume that the model assumptions reflect the real world reasonable well, we can use the standard error (SE) as an estimate of how far away in average the estimated $\beta_{1}$ may be from the underlying true value, i.e. a $\beta_{1}$ that we would measure if we had sampled a very high number of (i.e., all) observations.  


```{r}
summary(mod)
```

*  What does the output of the function `summary` tell us?


To draw a 95% compatibility interval around the regression line, we ﬁrst deﬁne new x-values for which we would like to have the ﬁtted values (about 100 points across the range of x will produce smooth-looking lines when connected by line segments). We save these new x-values within the new data.frame `newdat`.  (Fig. \@ref(fig:figlmer2)).

```{r figlmer2, fig.cap = "Regression with 95% credible interval of the posterior distribution of the ﬁtted values.", fig.asp=0.45}
# Calculate 95% CI
range(dat$time.num, na.rm=TRUE)
newdat <- data.frame(time.num = seq(7, 17, length=100))
newdat$fit <- predict(mod, newdata=newdat)
newdat$lwr <- predict(mod, interval="confidence", newdata=newdat)[,2]
newdat$upr <- predict(mod, interval="confidence", newdata=newdat)[,3]


plot(dat$time.num, dat$weight, xlab="Hour", ylab="Weight [g]", pch=16, col=rgb(0,0,0,0.5), cex=0.7)
lines(newdat$time.num, newdat$fit, lwd=2, col="brown")
lines(newdat$time.num, newdat$lwr, lwd=2, lty=3, col="brown")
lines(newdat$time.num, newdat$upr, lwd=2, lty=3, col="brown")

# Make the same plot using ggplot
#regplot <- 
#  ggplot(dat, aes(x = x, y = y)) +
#  geom_point() +
#  geom_abline(intercept = coef(mod)[1], slope=coef(mod)[2], lwd=1, col="blue") +
#  geom_line(data = newdat, aes(x = x, y = CrI_lo), lty = 3) +
#  geom_line(data = newdat, aes(x = x, y = CrI_up), lty = 3) +
#  labs(x = "Predictor (x)", y = "Outcome (y)")
#regplot
```


The uncertainty interval measures statistical uncertainty of the regression line, but it does not describe how new observations would scatter around the regression line. If we want to describe where future observations will be, we have to report the prediction interval (see online book, posterior predictive distribution), or present the data within the plot of the regression line. 

* How would you describe the results for a paper?
